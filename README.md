#PySpark Datalakes Project

Este projeto demonstra como configurar um ambiente de **engenharia de dados** utilizando:

- [Apache Spark](https://spark.apache.org/) (PySpark)
- [Delta Lake](https://delta.io/)
- [Apache Iceberg](https://iceberg.apache.org/)
- [JupyterLab](https://jupyter.org/)
- [MkDocs Material](https://squidfunk.github.io/mkdocs-material/) para documentação

---

## Requisitos

- Python **3.10+**
- [Poetry](https://python-poetry.org/) para gerenciamento de dependências
- Docker (opcional, mas recomendado para ambiente isolado)

---

## Instalação do Ambiente
Clone o repositório:
- bash
- git clone https://github.com/Freitas86/ENG_DADOS_SPARK.git
- cd ENG_DADOS_SPARK

---

## Instale as dependencias
- poetry install
- poetry shell

---

## Inicie o JupyterLab
- jupyter lab

